# Module 20 Report Template

## Overview of the Analysis

In this section, describe the analysis you completed for the machine learning models used in this Challenge. This might include:

* Explain the purpose of the analysis.
* Explain what financial information the data was on, and what you needed to predict.
* Provide basic information about the variables you were trying to predict (e.g., `value_counts`).
* Describe the stages of the machine learning process you went through as part of this analysis.
* Briefly touch on any methods you used (e.g., `LogisticRegression`, or any resampling method).

The purpose of this analysis is credi-risk classifiction by determining the loan status as 'high-risk'(1) and healthy loan (0). Several models will and reports will be made to determine such status. 



## Below is a key of the variables covered:

loan-status: Loan status determines if the person is eligible for a loan. In this module,a "1" indicates healthy loan while a "0" indicates a risk.

X: The X in found by isolating the loan status and keeping the rest of the columns. These are the features of the data.

y: The variable we want to isolate and predicting, in this case it's "loan-status".In other words this is the label.

value_counts: the amount of the variable/label present. We will use this function to determine the balance of the loan status.

logistic regression model: A logistic regression model is a statistical method used for binary classification tasks, where the goal is to predict the probability that an observation belongs to a particular category or class. It models the relationship between one or more independent variables (features) and a binary dependent variable (outcome) by estimating the probability of the outcome using a logistic function.

X_train: We use this variable to train the features of the dataset. 

X_test: A dataset containing the independent variables (features) used for testing the performance of a machine learning model.

y_train:We use this variable to train the labels of the dataset. 

y_test: A dataset containing the corresponding true labels or outcomes for the testing data, used for evaluating the predictions made by a machine learning model.

train_test_split: A function used to split a dataset into training and testing subsets. 

X_train.shape:Attribute representing the shape (dimensions) of the training dataset's feature matrix.

random_state: when running the code, it's a parameter used to ensure that randomization is the same for each dataset.

stratify:A parameter in train_test_split that ensures the distribution of classes in the original dataset is preserved in the training and testing datasets.

classifier:A machine learning model used for classification tasks.

classifier.fit:A method used to train a classifier on the training data.

classifier.score:A method used to evaluate the performance of a classifier on a testing dataset.

predictions: :Predicted labels or outcomes generated by a trained classifier on a testing dataset.

accuracy_score: A metric measuring the proportion of correctly classified instances out of the total instances.

confusion_matrix:A table used to evaluate the performance of a classification model, showing the counts of true positive, true negative, false positive, and false negative predictions.

classification_report: A summary report presenting key classification metrics such as precision, recall, and F1-score.

target_names:Names of the target classes or categories in a classification task. 

ros/RandomOverSampler:An algorithm used to address class imbalance by randomly oversampling the minority class.

X_res:Feature matrix after applying random oversampling. 

y_res:Target labels after applying random oversampling.

y_pred:Predicted labels generated by a classifier.

classifier.predict:A method used to predict labels for new data instances.

precision:  A metric measuring the proportion of correctly predicted positive cases out of all predicted positive cases.

recall: A metric measuring the proportion of correctly predicted positive cases out of all actual positive cases
.
f1-score:A metric that combines precision and recall into a single value, providing a balance between them. 

support:The number of actual occurrences of each class in the test set.

macro avg: The average of the metric scores calculated for each class, without considering class imbalance.

weighted avg: The average of the metric scores calculated for each class, considering class imbalance.  

## Imports:

import numpy as np

import pandas as pd

from pathlib import Path

from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression

from imblearn.over_sampling import RandomOverSampler



## Stages of Machine Learning Process:

Split the Data into Training and Testing Sets

Step 1: Read the lending_data.csv data from the Resources folder into a Pandas DataFrame.

Step 2: Create the labels set (y) from the “loan_status” column, and then create the features (X) 
DataFrame from the remaining columns.

Step 3: Check the balance of the labels variable (y) by using the value_counts function.

Step 4: Split the data into training and testing datasets by using train_test_split.

Create a Logistic Regression Model with the Original Data

Step 1: Fit a logistic regression model by using the training data (X_train and y_train).

Step 2: Save the predictions on the testing data labels by using the testing feature data (X_test) and the fitted model.

Step 3: Evaluate the model’s performance by doing the following:

   -Calculate the accuracy score of the model.
   
   -Generate a confusion matrix.
   
   -Print the classification report.

Predict a Logistic Regression Model with Resampled Training Data

Step 1: Use the RandomOverSampler module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points.

Step 2: Use the LogisticRegression classifier and the resampled data to fit the model and make predictions.

Step 3: Evaluate the model’s performance by doing the following:

  -Calculate the accuracy score of the model.
  
  -Generate a confusion matrix.
  
  -Print the classification report.



## Results

Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of all machine learning models.

* Machine Learning Model 1:Logistic Regression Model with the Original Data
  * Description of Model 1 Accuracy, Precision, and Recall scores.

<img width="532" alt="Credit_risk_classification_Model_1" src="https://github.com/torok839098/credit-risk-classification/assets/135182172/250fad8b-825c-4b85-8304-82adb1546b2a">


The logistic regression model predicted a high accuracy score of 99.2%. This can be seen through the confusion matrix,since the model has 18679 true negatives and 558 true positives. According to the classifcation report, we see that accuracy scores are higher, and the loan status has a score of 1.00 in all three areas (precision, recall, f1-score, support) means that the model was able to accurately predict the loan-status. Now, X has lower scores which could be from the false negatives and false positives. However, as always it's important to continue testing and reruning the model to improve accuracy.


* Machine Learning Model 2:Logistic Regression Model with Resampled Training Data
  * Description of Model 2 Accuracy, Precision, and Recall scores.

    <img width="532" alt="Credit_risk_classification_Model_2" src="https://github.com/torok839098/credit-risk-classification/assets/135182172/4de969f7-de88-4f55-a841-8ef7396b9c29">

The resampled logistic regression model predicted a high accuracy score of 99.5%.Compared with the previous confusion matrix,it produced fewer false negatives but it did produce higher false positives. True negatives are slightly lower by 11 while the true positives increased by 70. 

According to the classifcation report, we see that accuracy scores are higher, and the loan status has a score of 1.00 in all three areas (precision, recall, f1-score, support) means that the model was able to accurately predict healthy loan-status. High risk loans have same score for precision but increased in recall (1.00) and f1-score (0.93) . Recall in all categories listed in the report is 1.00. F1 score has a range of lower 90s to 1.00.Despite some decrease in some scores, having a few false negatives may have contributed to higher scores. Also the data was resampled which helps with imbalanced data, making it more valid. 



## Summary

Summarize the results of the machine learning models, and include a recommendation on the model to use, if any. For example:
* Which one seems to perform best? How do you know it performs best?
* Does performance depend on the problem we are trying to solve? (For example, is it more important to predict the `1`'s, or predict the `0`'s? )

If you do not recommend any of the models, please justify your reasoning.



The logistic regression model demonstrated strong predictive capability for both healthy (label 0) and high-risk (label 1) loans, achieving an impressive accuracy score of 99.2%. This was evidenced by the confusion matrix, which showed 18679 true negatives and 558 true positives. The classification report further supported this, with accuracy scores consistently high across precision, recall, f1-score, and support metrics, indicating precise predictions for loan status. However, there were slightly lower scores for the high-risk loan category, likely due to false negatives and false positives, suggesting room for improvement through continued testing and model refinement. On the other hand, when utilizing oversampled data, the resampled logistic regression model achieved an even higher accuracy score of 99.5%. While this resulted in fewer false negatives, there was a slight increase in false positives compared to the previous model. Despite these subtile differences, the classification report still displayed strong performance across precision, recall, and f1-score metrics for both healthy and high-risk loan categories. The resampling of data likely contributed to the improved model validity by addressing imbalanced data concerns.



The purpose as mentioned before is analyze credit-risk classification.So, whether or not one label is more important to predict would depend on that purpose/context. If I were to work in a car dealership, for example, the model would benift the company to determine which features can determine a high-risk loan and who to give this loan to. Another situation that loans are used is education. Something to consider is that is it feasible to give this person this particular loan, without considering other factors that could prevent the person from paying in the future? Now, both 'healthy' and 'high-risk' could both relate to your target clients/the business depending how you analyze it.Maybe you are a company that analyzes credit and gives recommendations, so this model is useful to group the clients and have insights of what features/labels need more improvement. Going back to car loans, you need to have a certain credit score to be approved for the loan, so using the model to predict which of those credit scores leads to an increase of the 'healthy' loan. Finally, maybe looking into the accuracy scores and confusion matrix as well, seeing how you can reduce the false negatives and positives. 





## References for this page

Definitions:

https://saturncloud.io/blog/what-is-randomstate-in-sklearnmodelselectiontraintestsplit-example/#:~:text=random_state%20is%20a%20parameter%20in,an%20example%20to%20demonstrate%20this.

https://stackoverflow.com/questions/34842405/parameter-stratify-from-method-train-test-split-scikit-learn#:~:text=In%20this%20context%2C%20stratification%20means,labels%20as%20the%20input%20dataset. 

https://builtin.com/data-science/precision-and-recall# 

https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f 

